{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train an S4 model on sequential CIFAR10 / sequential MNIST with PyTorch for demonstration purposes.\n",
    "This code borrows heavily from https://github.com/kuangliu/pytorch-cifar.\n",
    "\n",
    "This file only depends on the standalone S4 layer\n",
    "available in /models/s4/\n",
    "\n",
    "* Train standard sequential CIFAR:\n",
    "    python -m example\n",
    "* Train sequential CIFAR grayscale:\n",
    "    python -m example --grayscale\n",
    "* Train MNIST:\n",
    "    python -m example --dataset mnist --d_model 256 --weight_decay 0.0\n",
    "\n",
    "The `S4Model` class defined in this file provides a simple backbone to train S4 models.\n",
    "This backbone is a good starting point for many problems, although some tasks (especially generation)\n",
    "may require using other backbones.\n",
    "\n",
    "The default CIFAR10 model trained by this file should get\n",
    "89+% accuracy on the CIFAR10 test set in 80 epochs.\n",
    "\n",
    "Each epoch takes approximately 7m20s on a T4 GPU (will be much faster on V100 / A100).\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# Optimizer\n",
    "parser.add_argument('--lr', default=0.01, type=float, help='Learning rate')\n",
    "parser.add_argument('--weight_decay', default=0.01, type=float, help='Weight decay')\n",
    "# Scheduler\n",
    "# parser.add_argument('--patience', default=10, type=float, help='Patience for learning rate scheduler')\n",
    "parser.add_argument('--epochs', default=100, type=float, help='Training epochs')\n",
    "# Dataset\n",
    "parser.add_argument('--dataset', default='cifar10', choices=['mnist', 'cifar10'], type=str, help='Dataset')\n",
    "parser.add_argument('--grayscale', action='store_true', help='Use grayscale CIFAR10')\n",
    "# Dataloader\n",
    "parser.add_argument('--num_workers', default=4, type=int, help='Number of workers to use for dataloader')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='Batch size')\n",
    "# Model\n",
    "parser.add_argument('--n_layers', default=4, type=int, help='Number of layers')\n",
    "parser.add_argument('--d_model', default=128, type=int, help='Model dimension')\n",
    "parser.add_argument('--dropout', default=0.1, type=float, help='Dropout')\n",
    "parser.add_argument('--prenorm', action='store_true', help='Prenorm')\n",
    "# General\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='Resume from checkpoint')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print(f'==> Preparing {args.dataset} data..')\n",
    "\n",
    "def split_train_val(train, val_split):\n",
    "    train_len = int(len(train) * (1.0-val_split))\n",
    "    train, val = torch.utils.data.random_split(\n",
    "        train,\n",
    "        (train_len, len(train) - train_len),\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "    return train, val\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "\n",
    "    if args.grayscale:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=122.6 / 255.0, std=61.0 / 255.0),\n",
    "            transforms.Lambda(lambda x: x.view(1, 1024).t())\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            transforms.Lambda(lambda x: x.view(3, 1024).t())\n",
    "        ])\n",
    "\n",
    "    # S4 is trained on sequences with no data augmentation!\n",
    "    transform_train = transform_test = transform\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=True, download=True, transform=transform_train)\n",
    "    trainset, _ = split_train_val(trainset, val_split=0.1)\n",
    "\n",
    "    valset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=True, download=True, transform=transform_test)\n",
    "    _, valset = split_train_val(valset, val_split=0.1)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    d_input = 3 if not args.grayscale else 1\n",
    "    d_output = 10\n",
    "\n",
    "elif args.dataset == 'mnist':\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.view(1, 784).t())\n",
    "    ])\n",
    "    transform_train = transform_test = transform\n",
    "\n",
    "    trainset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainset, _ = split_train_val(trainset, val_split=0.1)\n",
    "\n",
    "    valset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform_test)\n",
    "    _, valset = split_train_val(valset, val_split=0.1)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    d_input = 1\n",
    "    d_output = 10\n",
    "else: raise NotImplementedError\n",
    "\n",
    "# Dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S4Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output=10,\n",
    "        d_model=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.2,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                S4D(d_model, dropout=dropout, transposed=True, lr=min(0.001, args.lr))\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_optimizer(model, lr, weight_decay, epochs):\n",
    "    \"\"\"\n",
    "    S4 requires a specific optimizer setup.\n",
    "\n",
    "    The S4 layer (A, B, C, dt) parameters typically\n",
    "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
    "\n",
    "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
    "    and weight decay (if desired).\n",
    "    \"\"\"\n",
    "\n",
    "    # All parameters in the model\n",
    "    all_parameters = list(model.parameters())\n",
    "\n",
    "    # General parameters don't contain the special _optim key\n",
    "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
    "\n",
    "    # Create an optimizer with the general parameters\n",
    "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Add parameters with special hyperparameters\n",
    "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
    "    hps = [\n",
    "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
    "    ]  # Unique dicts\n",
    "    for hp in hps:\n",
    "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp]\n",
    "        optimizer.add_param_group(\n",
    "            {\"params\": params, **hp}\n",
    "        )\n",
    "\n",
    "    # Create a lr scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    # Print optimizer info\n",
    "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        group_hps = {k: g.get(k, None) for k in keys}\n",
    "        print(' | '.join([\n",
    "            f\"Optimizer group {i}\",\n",
    "            f\"{len(g['params'])} tensors\",\n",
    "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Everything after this point is standard PyTorch training!\n",
    "###############################################################################\n",
    "\n",
    "# Training\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    for batch_idx, (inputs, targets) in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "            (batch_idx, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "        )\n",
    "\n",
    "\n",
    "def eval(epoch, dataloader, checkpoint=False):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(dataloader))\n",
    "        for batch_idx, (inputs, targets) in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description(\n",
    "                'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                (batch_idx, len(dataloader), eval_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "            )\n",
    "\n",
    "    # Save checkpoint.\n",
    "    if checkpoint:\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "        return acc\n",
    "\n",
    "pbar = tqdm(range(start_epoch, args.epochs))\n",
    "for epoch in pbar:\n",
    "    if epoch == 0:\n",
    "        pbar.set_description('Epoch: %d' % (epoch))\n",
    "    else:\n",
    "        pbar.set_description('Epoch: %d | Val acc: %1.3f' % (epoch, val_acc))\n",
    "    train()\n",
    "    val_acc = eval(epoch, valloader, checkpoint=True)\n",
    "    eval(epoch, testloader)\n",
    "    scheduler.step()\n",
    "    # print(f\"Epoch {epoch} learning rate: {scheduler.get_last_lr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from s4 import S4Block as S4  # Can use full version instead of minimal S4D standalone below\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Dropout broke in PyTorch 1.11\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):\n",
    "    print(\"WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.\")\n",
    "    dropout_fn = nn.Dropout\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):\n",
    "    dropout_fn = nn.Dropout1d\n",
    "else:\n",
    "    dropout_fn = nn.Dropout2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "from s4 import S4Block as S4 \n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, feature_num]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(1)].unsqueeze(0)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "\n",
    "class S4ModelForRUL(nn.Module):\n",
    "    def __init__(self, d_input, d_model=512, n_layers=4, dropout=0.1, max_len=500):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout=dropout, max_len=max_len)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "        self.bn_encoder = nn.BatchNorm1d(max_len) \n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(S4(d_model, dropout=dropout, transposed=True))\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "       \n",
    "        src = self.encoder(src)  # [batch_size, seq_len, d_input] -> [batch_size, seq_len, d_model]\n",
    "          # Apply tanh activation function\n",
    "        src = self.bn_encoder(src)  \n",
    "        src = F.tanh(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        src = src.transpose(1, 2)  # S4 expects [batch_size, d_model, seq_len]\n",
    "        for layer in self.s4_layers:\n",
    "            src, _ = layer(src)  # We ignore the state output here\n",
    "        src = src.transpose(1, 2)  # Back to [batch_size, seq_len, d_model]\n",
    "        src = self.dropout(src)\n",
    "        output = self.decoder(src) \n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class load_data(Dataset):\n",
    "    \"\"\"\n",
    "    root = new | old\n",
    "    \"\"\"\n",
    "    def __init__(self, name, seq_len, root='new') -> None:\n",
    "        super().__init__()\n",
    "        data_root = \"data/units/\"\n",
    "        if root == 'old':\n",
    "            label_root = \"data/labels/\"\n",
    "        elif root == 'new':\n",
    "            label_root = \"data/new_labels/\"\n",
    "        else:\n",
    "            raise RuntimeError(\"got invalid parameter root='{}'\".format(root))\n",
    "        raw = np.loadtxt(data_root+name)[:,2:]\n",
    "        lbl = np.loadtxt(label_root+name)/Rc\n",
    "        l = len(lbl)\n",
    "        if l<seq_len:\n",
    "            raise RuntimeError(\"seq_len {} is too big for file '{}' with length {}\".format(seq_len, name, l))\n",
    "        raw, lbl = torch.tensor(raw, dtype=torch.float), torch.tensor(lbl, dtype=torch.float)\n",
    "        lbl_pad_0 = [torch.ones([seq_len-i-1]) for i in range(seq_len-1)] \n",
    "        data_pad_0 = [torch.zeros([seq_len-i-1,24]) for i in range(seq_len-1)]\n",
    "        lbl_pad_1 = [torch.zeros([i+1]) for i in range(seq_len-1)] \n",
    "        data_pad_1 = [torch.zeros([i+1,24]) for i in range(seq_len-1)]\n",
    "        self.data = [torch.cat([data_pad_0[i],raw[:i+1]],0) for i in range(seq_len-1)] \n",
    "        self.data += [raw[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "        self.data += [torch.cat([raw[l-seq_len+i+1:], data_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "        self.label = [torch.cat([lbl_pad_0[i],lbl[:i+1]],0) for i in range(seq_len-1)] \n",
    "        self.label += [lbl[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "        self.label += [torch.cat([lbl[l-seq_len+i+1:], lbl_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "        self.padding = [torch.cat([torch.ones(seq_len-i-1), torch.zeros(i+1)],0) for i in range(seq_len-1)]   # 1 for ingore\n",
    "        self.padding += [torch.zeros(seq_len) for i in range(seq_len-1, l)]\n",
    "        self.padding += [torch.cat([torch.zeros(seq_len-i-1), torch.ones(i+1)],0) for i in range(seq_len-1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index], self.padding[index]\n",
    "\n",
    "\n",
    "class load_all_data(Dataset):\n",
    "    \"\"\"\n",
    "    root: new | old\n",
    "    name: LIST of txt files to collect \n",
    "    \"\"\"\n",
    "    def __init__(self, name, seq_len) -> None:\n",
    "        super().__init__()\n",
    "        data_root = \"data/units/\"\n",
    "        label_root = \"data/new_labels/\"\n",
    "        lis = os.listdir(data_root)\n",
    "        data_list = [i for i in lis if i in name]\n",
    "        self.data, self.label, self.padding = [], [], []\n",
    "        for n in data_list:\n",
    "            raw = np.loadtxt(data_root+n)[:,2:]\n",
    "            lbl = np.loadtxt(label_root+n)/Rc\n",
    "            l = len(lbl)\n",
    "            if l<seq_len:\n",
    "                raise RuntimeError(\"seq_len {} is too big for file '{}' with length {}\".format(seq_len, n, l))\n",
    "            raw, lbl = torch.tensor(raw, dtype=torch.float), torch.tensor(lbl, dtype=torch.float)\n",
    "            lbl_pad_0 = [torch.ones([seq_len-i-1]) for i in range(seq_len-1)] \n",
    "            data_pad_0 = [torch.zeros([seq_len-i-1,24]) for i in range(seq_len-1)]\n",
    "            lbl_pad_1 = [torch.zeros([i+1]) for i in range(seq_len-1)] \n",
    "            data_pad_1 = [torch.zeros([i+1,24]) for i in range(seq_len-1)]\n",
    "            self.data += [torch.cat([data_pad_0[i],raw[:i+1]],0) for i in range(seq_len-1)] \n",
    "            self.data += [raw[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "            self.data += [torch.cat([raw[l-seq_len+i+1:], data_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "            self.label += [torch.cat([lbl_pad_0[i],lbl[:i+1]],0) for i in range(seq_len-1)] \n",
    "            self.label += [lbl[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "            self.label += [torch.cat([lbl[l-seq_len+i+1:], lbl_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "            self.padding += [torch.cat([torch.ones(seq_len-i-1), torch.zeros(i+1)],0) for i in range(seq_len-1)]   # 1 for ingore\n",
    "            self.padding += [torch.zeros(seq_len) for i in range(seq_len-1, l)]\n",
    "            self.padding += [torch.cat([torch.zeros(seq_len-i-1), torch.ones(i+1)],0) for i in range(seq_len-1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index], self.padding[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'FD001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.loadtxt(\"save/\"+name+\"/train\"+name+\".txt\", dtype=str).tolist()\n",
    "val = np.loadtxt(\"save/\"+name+\"/valid\"+name+\".txt\", dtype=str).tolist()\n",
    "ts = np.loadtxt(\"save/\"+name+\"/test\"+name+\".txt\", dtype=str).tolist()\n",
    "\n",
    "target = ts+val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer group 0 | 9 tensors | weight_decay 0.0001\n",
      "Optimizer group 1 | 1 tensors | weight_decay 0.0001\n",
      "Optimizer group 2 | 5 tensors | weight_decay 0.0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n",
    "d_input = 24  \n",
    "seq_len = 70\n",
    "Rc = 130\n",
    "model = S4ModelForRUL(d_input=d_input, d_model=512, n_layers=1, dropout=0.1, max_len=seq_len)\n",
    "model.to(device)\n",
    "Loss = nn.MSELoss()\n",
    "Loss.to(device)\n",
    "\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# sch = torch.optim.lr_scheduler.StepLR(opt, 50, 0.5)\n",
    "epochs = 100\n",
    "opt, sch = setup_optimizer(\n",
    "    model, lr=0.02, weight_decay=1e-4, epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 14.088769018209565, RMSE: 13.985892764445618\n",
      "Epoch: 1, Loss: 0.01889443943100805, RMSE: 11.91389800098081\n",
      "Epoch: 2, Loss: 0.014130031960588452, RMSE: 12.433026148023858\n",
      "Epoch: 3, Loss: 0.013327636051218252, RMSE: 12.71205144021184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 86\u001b[0m\n\u001b[1;32m     81\u001b[0m                 total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m rmse\n\u001b[1;32m     82\u001b[0m         \u001b[39mreturn\u001b[39;00m total_loss\u001b[39m*\u001b[39mRc\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(val_data)\n\u001b[0;32m---> 86\u001b[0m train(tr, model, Loss, opt, seq_len, epochs, device, name)\n",
      "Cell \u001b[0;32mIn[46], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data, model, loss_function, optimizer, seq_len, epochs, device, name)\u001b[0m\n\u001b[1;32m     17\u001b[0m train_data, train_label \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mto(device), train_label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m output \u001b[39m=\u001b[39m model(train_data)\u001b[39m.\u001b[39msqueeze()  \u001b[39m# Adjusted to pass only train_data\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, train_label)\n\u001b[1;32m     23\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mS4ModelForRUL.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     51\u001b[0m src \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# S4 expects [batch_size, d_model, seq_len]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms4_layers:\n\u001b[0;32m---> 53\u001b[0m     src, _ \u001b[39m=\u001b[39m layer(src)  \u001b[39m# We ignore the state output here\u001b[39;00m\n\u001b[1;32m     54\u001b[0m src \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# Back to [batch_size, seq_len, d_model]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(src)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/RUL/RUL/Baseline/s4.py:1919\u001b[0m, in \u001b[0;36mS4Block.forward\u001b[0;34m(self, x, lengths, **kwargs)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbottleneck \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1917\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_linear(x)\n\u001b[0;32m-> 1919\u001b[0m y, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1922\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1923\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_gate(y)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/RUL/RUL/Baseline/s4.py:1712\u001b[0m, in \u001b[0;36mFFTConv.forward\u001b[0;34m(self, x, state, rate, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# Compute SS Kernel\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m l_kernel \u001b[39m=\u001b[39m L \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mmin\u001b[39m(L, \u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mL \u001b[39m/\u001b[39m rate))\n\u001b[0;32m-> 1712\u001b[0m k, k_state \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(L\u001b[39m=\u001b[39;49ml_kernel, rate\u001b[39m=\u001b[39;49mrate, state\u001b[39m=\u001b[39;49mstate) \u001b[39m# (C H L) (B C H L)\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m \u001b[39m# Convolution\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rul/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/RUL/RUL/Baseline/s4.py:1385\u001b[0m, in \u001b[0;36mSSMKernelDPLR.forward\u001b[0;34m(self, state, rate, L)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     cauchy_mult \u001b[39m=\u001b[39m cauchy_naive\n\u001b[1;32m   1384\u001b[0m \u001b[39m# Calculate resolvent at omega\u001b[39;00m\n\u001b[0;32m-> 1385\u001b[0m r \u001b[39m=\u001b[39m cauchy_mult(v, z, A)\n\u001b[1;32m   1387\u001b[0m \u001b[39m# Low-rank Woodbury correction\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/RUL/RUL/Baseline/s4.py:164\u001b[0m, in \u001b[0;36mcauchy_naive\u001b[0;34m(v, z, w)\u001b[0m\n\u001b[1;32m    162\u001b[0m w \u001b[39m=\u001b[39m _conj(w)\n\u001b[1;32m    163\u001b[0m cauchy_matrix \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m (z\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m w\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m# (... N L)\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49msum(cauchy_matrix, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "import math\n",
    "\n",
    "def train(data, model, loss_function, optimizer, seq_len, epochs, device, name):\n",
    "    min_rmse = float('inf')\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        random.shuffle(data)\n",
    "        train_data = load_all_data(data, seq_len=seq_len)  # Ensure this returns a dataset compatible with DataLoader\n",
    "        total_loss = 0.0\n",
    "        train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "       \n",
    "        for train_data, train_label, train_padding in train_loader:\n",
    "            \n",
    "            train_data, train_label = train_data.to(device), train_label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data).squeeze()  # Adjusted to pass only train_data\n",
    "            \n",
    "            \n",
    "            loss = loss_function(output, train_label)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "       \n",
    "        \n",
    "        rmse = validate(model, seq_len, device, target)  # Adjust validate function call accordingly\n",
    "        print(f\"Epoch: {e}, Loss: {total_loss / len(train_loader)}, RMSE: {rmse}\")\n",
    "        \n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            torch.save(model.state_dict(), f'save/s4_{name}.pth')\n",
    "        \n",
    "        sch.step()\n",
    "    \n",
    "    return min_rmse\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "def validate(model, seq_len, device, val_data):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i in val_data:\n",
    "            pred_sum, pred_cnt = torch.zeros(800), torch.zeros(800)\n",
    "            valid_data = load_data(i, seq_len)  # Ensure this returns a dataset compatible with DataLoader\n",
    "            valid_loader = DataLoader(valid_data, batch_size=1000, shuffle=False)\n",
    "            \n",
    "           \n",
    "            for valid_data, valid_label, valid_padding in valid_loader:\n",
    "               \n",
    "                valid_data = valid_data.to(device)\n",
    "                data_len = len(valid_data)\n",
    "                output = model(valid_data).squeeze(2).cpu()  # Adjusted to pass only valid_data\n",
    "                # Proceed with your RMSE calculation\n",
    "\n",
    "                \n",
    "                \n",
    "                for j in range(data_len):\n",
    "                    if j < seq_len-1:\n",
    "                    \n",
    "                        pred_sum[:j+1] += output[j, -(j+1):]\n",
    "                        pred_cnt[:j+1] += 1\n",
    "                    elif j <= data_len-seq_len:\n",
    "                        pred_sum[j-seq_len+1:j+1] += output[j]\n",
    "                        pred_cnt[j-seq_len+1:j+1] += 1\n",
    "                    else:\n",
    "                        pred_sum[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += output[j, :(data_len-j)]\n",
    "                        pred_cnt[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += 1\n",
    "                truth = torch.tensor([valid_label[j,-1] for j in range(len(valid_label)-seq_len+1)], dtype=torch.float)\n",
    "                pred_sum, pred_cnt = pred_sum[:data_len-seq_len+1], pred_cnt[:data_len-seq_len+1]\n",
    "                pred = pred_sum/pred_cnt\n",
    "                mse = float(torch.sum(torch.pow(pred-truth, 2)))\n",
    "                rmse = math.sqrt(mse/data_len)\n",
    "                total_loss += rmse\n",
    "        return total_loss*Rc/len(val_data)\n",
    "                \n",
    "               \n",
    "\n",
    "train(tr, model, Loss, opt, seq_len, epochs, device, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pred, truth):\n",
    "    \"\"\"input must be tensors!\"\"\"\n",
    "    x = pred-truth\n",
    "    score1 = torch.tensor([torch.exp(-i/13)-1 for i in x if i<0])\n",
    "    score2 = torch.tensor([torch.exp(i/10)-1 for i in x if i>=0])\n",
    "    return int(torch.sum(score1)+torch.sum(score2))\n",
    "\n",
    "\n",
    "def get_pred_result(data_len, out, lb):\n",
    "    pred_sum, pred_cnt = torch.zeros(800), torch.zeros(800)\n",
    "    for j in range(data_len):\n",
    "        if j < seq_len-1:\n",
    "            pred_sum[:j+1] += out[j, -(j+1):]\n",
    "            pred_cnt[:j+1] += 1\n",
    "        elif j <= data_len-seq_len:\n",
    "            pred_sum[j-seq_len+1:j+1] += out[j]\n",
    "            pred_cnt[j-seq_len+1:j+1] += 1\n",
    "        else:\n",
    "            pred_sum[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += out[j, :(data_len-j)]\n",
    "            pred_cnt[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += 1\n",
    "    truth = torch.tensor([lb[j,-1] for j in range(len(lb[0])-seq_len+1)], dtype=torch.float)\n",
    "    \n",
    "    pred_sum, pred_cnt = pred_sum[:data_len-seq_len+1], pred_cnt[:data_len-seq_len+1]\n",
    "    pred2 = pred_sum/pred_cnt\n",
    "    pred2 *= Rc\n",
    "    truth *= Rc\n",
    "    return truth, pred2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for file FD001-22.txt: rmse=54.3685, score=230763\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-23.txt: rmse=50.4937, score=179187\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-36.txt: rmse=51.2551, score=180114\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-8.txt: rmse=52.1057, score=184408\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-10.txt: rmse=45.8891, score=175925\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-4.txt: rmse=48.6467, score=217472\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-83.txt: rmse=44.1214, score=222225\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-86.txt: rmse=49.0491, score=248496\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-84.txt: rmse=49.7693, score=226900\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-19.txt: rmse=53.9262, score=204862\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-2.txt: rmse=44.6266, score=241481\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-88.txt: rmse=50.1915, score=205370\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-56.txt: rmse=51.7572, score=306188\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-82.txt: rmse=47.7710, score=220262\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-43.txt: rmse=47.5411, score=217500\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-15.txt: rmse=47.5313, score=200785\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-33.txt: rmse=46.4076, score=185620\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-61.txt: rmse=47.9862, score=215835\n",
      "--------------------------------------------------------------------------------\n",
      "tested on [70] files, mean RMSE = 12.6205, mean score = 55191\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming you have a 'load_data' or 'load_all_data' class for handling test datasets\n",
    "# and the 'score' function for scoring the predictions.\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    model = S4ModelForRUL(d_input=24, d_model=512, n_layers=1, dropout=0.1, max_len=70)  # Adjust parameters as necessary\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def test_model(model, test_data, seq_len, device):\n",
    "    tot = 0.0\n",
    "    tot_sc= 0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(test_len):\n",
    "            i = next(test_iter)\n",
    "            \n",
    "            test_dataset = load_data(i, seq_len=seq_len)  # Adjust depending on your data loader\n",
    "            data_len = len(test_dataset)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)  # Batch size can be adjusted\n",
    "            it = iter(test_loader)\n",
    "            d = next(it)\n",
    "            input, lb, msk = d[0], d[1], d[2]\n",
    "            input = input.to(device)\n",
    "            predictions = model(input).squeeze(2)\n",
    "            \n",
    "            truth, pred = get_pred_result(data_len,  predictions.to('cpu'), lb.to('cpu'))\n",
    "            \n",
    "            mse = float(torch.sum(torch.pow(pred-truth, 2)))\n",
    "            rmse = math.sqrt(mse/data_len)\n",
    "            tot += rmse\n",
    "            sc = score(pred, truth)\n",
    "            tot_sc += sc\n",
    "            print(\"for file {}: rmse={:.4f}, score={}\".format(i, rmse, sc))\n",
    "            print('-'*80)\n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    avg_rmse = tot / len(test_data)\n",
    "    avg_score = tot_sc / len(test_data)\n",
    "    print(\"tested on [{}] files, mean RMSE = {:.4f}, mean score = {}\".format(len(test_data), tot/len(test_data), int(tot_sc/len(test_data))))\n",
    "    \n",
    "    return avg_rmse, avg_score\n",
    "\n",
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'  # Adjust the device as needed\n",
    "model_path = 'save/s4_FD001.pth'  # Adjust the path to your saved model\n",
    "\n",
    "test_data = tr  # Your test set file names\n",
    "test_len = len(ts)\n",
    "test_iter = iter(ts)\n",
    "\n",
    "model = load_model(model_path, device)\n",
    "avg_rmse, avg_score = test_model(model, test_data, seq_len, device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for file FD001-35.txt: rmse=58.6192, score=8900991\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-71.txt: rmse=55.7260, score=8901015\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-43.txt: rmse=55.8255, score=8901015\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-24.txt: rmse=63.0116, score=8900959\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-10.txt: rmse=54.3877, score=8901028\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-73.txt: rmse=55.2365, score=8901019\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-31.txt: rmse=53.3155, score=8901039\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-61.txt: rmse=58.1615, score=8900995\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-44.txt: rmse=57.3862, score=8901000\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-33.txt: rmse=56.5375, score=8901008\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-2.txt: rmse=49.2507, score=8901088\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-34.txt: rmse=57.0634, score=8901003\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-12.txt: rmse=59.9368, score=8900981\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-26.txt: rmse=56.6415, score=8901007\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-8.txt: rmse=62.5831, score=8900962\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-22.txt: rmse=56.3312, score=8901010\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-21.txt: rmse=57.0634, score=8901003\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-53.txt: rmse=57.0634, score=8901003\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-4.txt: rmse=57.7146, score=8900998\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-94.txt: rmse=51.3518, score=8901061\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-77.txt: rmse=62.0254, score=8900966\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-84.txt: rmse=50.6706, score=8901069\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-36.txt: rmse=61.4825, score=8900969\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-69.txt: rmse=44.8428, score=8901157\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-40.txt: rmse=57.8253, score=8900997\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-70.txt: rmse=64.5070, score=8900950\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-47.txt: rmse=55.1402, score=8901020\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-45.txt: rmse=61.4825, score=8900969\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-3.txt: rmse=58.8522, score=8900989\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-99.txt: rmse=58.1615, score=8900995\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-75.txt: rmse=53.7543, score=8901034\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-41.txt: rmse=54.9491, score=8901023\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-17.txt: rmse=50.0163, score=8901078\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-48.txt: rmse=53.5774, score=8901036\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-65.txt: rmse=62.1634, score=8900965\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-55.txt: rmse=57.2779, score=8901001\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-56.txt: rmse=50.0877, score=8901077\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-32.txt: rmse=57.4950, score=8901000\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-92.txt: rmse=45.9534, score=8901137\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-78.txt: rmse=53.5774, score=8901036\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-98.txt: rmse=61.7521, score=8900968\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-11.txt: rmse=52.8031, score=8901044\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-19.txt: rmse=61.4825, score=8900969\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-95.txt: rmse=49.5249, score=8901084\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-85.txt: rmse=57.8253, score=8900997\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-81.txt: rmse=52.8031, score=8901044\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-76.txt: rmse=55.5286, score=8901017\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-66.txt: rmse=56.3312, score=8901010\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-6.txt: rmse=57.8253, score=8900997\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-100.txt: rmse=56.5375, score=8901008\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-59.txt: rmse=53.5774, score=8901036\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-63.txt: rmse=59.4473, score=8900984\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-67.txt: rmse=47.5753, score=8901112\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-38.txt: rmse=57.1703, score=8901003\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-90.txt: rmse=62.0254, score=8900966\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-91.txt: rmse=64.8192, score=8900948\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-37.txt: rmse=59.9368, score=8900981\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-23.txt: rmse=60.1862, score=8900979\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-58.txt: rmse=63.0116, score=8900959\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-20.txt: rmse=53.3155, score=8901039\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-82.txt: rmse=55.1402, score=8901020\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-93.txt: rmse=61.8883, score=8900966\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-52.txt: rmse=55.2365, score=8901019\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-79.txt: rmse=56.6415, score=8901007\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-83.txt: rmse=48.8480, score=8901092\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-9.txt: rmse=56.4341, score=8901009\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-51.txt: rmse=55.2365, score=8901019\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-96.txt: rmse=46.2306, score=8901132\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-88.txt: rmse=55.2365, score=8901019\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-50.txt: rmse=56.7461, score=8901006\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-13.txt: rmse=60.8239, score=8900974\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-87.txt: rmse=58.9698, score=8900988\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-16.txt: rmse=55.6271, score=8901016\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-7.txt: rmse=51.2747, score=8901061\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-39.txt: rmse=65.9477, score=8900941\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-46.txt: rmse=51.5071, score=8901059\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-80.txt: rmse=58.1615, score=8900995\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-49.txt: rmse=55.0444, score=8901022\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-25.txt: rmse=53.6657, score=8901036\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-42.txt: rmse=56.9570, score=8901004\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-15.txt: rmse=55.8255, score=8901015\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-18.txt: rmse=57.0634, score=8901003\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-1.txt: rmse=57.3862, score=8901000\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-54.txt: rmse=51.4293, score=8901060\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-68.txt: rmse=56.6415, score=8901007\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-97.txt: rmse=56.3312, score=8901010\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-14.txt: rmse=58.7354, score=8900990\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-60.txt: rmse=59.6905, score=8900982\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-64.txt: rmse=49.5249, score=8901084\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-30.txt: rmse=57.1703, score=8901003\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-74.txt: rmse=60.4388, score=8900976\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-62.txt: rmse=58.7354, score=8900990\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-72.txt: rmse=55.2365, score=8901019\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-89.txt: rmse=54.8543, score=8901024\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-5.txt: rmse=50.5229, score=8901071\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-57.txt: rmse=64.5070, score=8900950\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-28.txt: rmse=60.5664, score=8900976\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-86.txt: rmse=49.8744, score=8901080\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-29.txt: rmse=60.8239, score=8900974\n",
      "--------------------------------------------------------------------------------\n",
      "for file FD001-27.txt: rmse=61.7521, score=8900968\n",
      "--------------------------------------------------------------------------------\n",
      "tested on [100] files, mean RMSE = 56.4326, mean score = 8901013\n"
     ]
    }
   ],
   "source": [
    "x=torch.load(f'save/s4_{name}.pth', map_location='cuda:2')\n",
    "model.load_state_dict(x)\n",
    "data_root = \"data/units/\"\n",
    "label_root = \"data/labels/\"\n",
    "lis = os.listdir(data_root)\n",
    "test_list = [i for i in lis if i[:5] == name]\n",
    "random.shuffle(test_list)\n",
    "test_len = len(test_list)\n",
    "list_iter = iter(test_list)\n",
    "test()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('rul')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba6a37c31782f78b489b06366919d70a54943a1b5ed282f036807a93db564a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
