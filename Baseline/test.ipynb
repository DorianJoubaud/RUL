{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'FD001'\n",
    "seq_len = 30\n",
    "Rc = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load_data(Dataset):\n",
    "    \"\"\"\n",
    "    root = new | old\n",
    "    \"\"\"\n",
    "    def __init__(self, name, seq_len, root='new') -> None:\n",
    "        super().__init__()\n",
    "        data_root = \"data/units/\"\n",
    "        if root == 'old':\n",
    "            label_root = \"data/labels/\"\n",
    "        elif root == 'new':\n",
    "            label_root = \"data/new_labels/\"\n",
    "        else:\n",
    "            raise RuntimeError(\"got invalid parameter root='{}'\".format(root))\n",
    "        raw = np.loadtxt(data_root+name)[:,2:]\n",
    "        lbl = np.loadtxt(label_root+name)/Rc\n",
    "        l = len(lbl)\n",
    "        if l<seq_len:\n",
    "            raise RuntimeError(\"seq_len {} is too big for file '{}' with length {}\".format(seq_len, name, l))\n",
    "        raw, lbl = torch.tensor(raw, dtype=torch.float), torch.tensor(lbl, dtype=torch.float)\n",
    "        lbl_pad_0 = [torch.ones([seq_len-i-1]) for i in range(seq_len-1)] \n",
    "        data_pad_0 = [torch.zeros([seq_len-i-1,24]) for i in range(seq_len-1)]\n",
    "        lbl_pad_1 = [torch.zeros([i+1]) for i in range(seq_len-1)] \n",
    "        data_pad_1 = [torch.zeros([i+1,24]) for i in range(seq_len-1)]\n",
    "        self.data = [torch.cat([data_pad_0[i],raw[:i+1]],0) for i in range(seq_len-1)] \n",
    "        self.data += [raw[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "        self.data += [torch.cat([raw[l-seq_len+i+1:], data_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "        self.label = [torch.cat([lbl_pad_0[i],lbl[:i+1]],0) for i in range(seq_len-1)] \n",
    "        self.label += [lbl[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "        self.label += [torch.cat([lbl[l-seq_len+i+1:], lbl_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "        self.padding = [torch.cat([torch.ones(seq_len-i-1), torch.zeros(i+1)],0) for i in range(seq_len-1)]   # 1 for ingore\n",
    "        self.padding += [torch.zeros(seq_len) for i in range(seq_len-1, l)]\n",
    "        self.padding += [torch.cat([torch.zeros(seq_len-i-1), torch.ones(i+1)],0) for i in range(seq_len-1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index], self.padding[index]\n",
    "\n",
    "\n",
    "class load_all_data(Dataset):\n",
    "    \"\"\"\n",
    "    root: new | old\n",
    "    name: LIST of txt files to collect \n",
    "    \"\"\"\n",
    "    def __init__(self, name, seq_len) -> None:\n",
    "        super().__init__()\n",
    "        data_root = \"data/units/\"\n",
    "        label_root = \"data/new_labels/\"\n",
    "        lis = os.listdir(data_root)\n",
    "        data_list = [i for i in lis if i in name]\n",
    "        self.data, self.label, self.padding = [], [], []\n",
    "        for n in data_list:\n",
    "            raw = np.loadtxt(data_root+n)[:,2:]\n",
    "            lbl = np.loadtxt(label_root+n)/Rc\n",
    "            l = len(lbl)\n",
    "            if l<seq_len:\n",
    "                raise RuntimeError(\"seq_len {} is too big for file '{}' with length {}\".format(seq_len, n, l))\n",
    "            raw, lbl = torch.tensor(raw, dtype=torch.float), torch.tensor(lbl, dtype=torch.float)\n",
    "            lbl_pad_0 = [torch.ones([seq_len-i-1]) for i in range(seq_len-1)] \n",
    "            data_pad_0 = [torch.zeros([seq_len-i-1,24]) for i in range(seq_len-1)]\n",
    "            lbl_pad_1 = [torch.zeros([i+1]) for i in range(seq_len-1)] \n",
    "            data_pad_1 = [torch.zeros([i+1,24]) for i in range(seq_len-1)]\n",
    "            self.data += [torch.cat([data_pad_0[i],raw[:i+1]],0) for i in range(seq_len-1)] \n",
    "            self.data += [raw[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "            self.data += [torch.cat([raw[l-seq_len+i+1:], data_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "            self.label += [torch.cat([lbl_pad_0[i],lbl[:i+1]],0) for i in range(seq_len-1)] \n",
    "            self.label += [lbl[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "            self.label += [torch.cat([lbl[l-seq_len+i+1:], lbl_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "            self.padding += [torch.cat([torch.ones(seq_len-i-1), torch.zeros(i+1)],0) for i in range(seq_len-1)]   # 1 for ingore\n",
    "            self.padding += [torch.zeros(seq_len) for i in range(seq_len-1, l)]\n",
    "            self.padding += [torch.cat([torch.zeros(seq_len-i-1), torch.ones(i+1)],0) for i in range(seq_len-1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index], self.padding[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.loadtxt(\"save/\"+name+\"/train\"+name+\".txt\", dtype=str).tolist()\n",
    "val = np.loadtxt(\"save/\"+name+\"/valid\"+name+\".txt\", dtype=str).tolist()\n",
    "ts = np.loadtxt(\"save/\"+name+\"/test\"+name+\".txt\", dtype=str).tolist()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "model = transformer(max_len=seq_len)\n",
    "model.to(device)\n",
    "Loss = nn.MSELoss()\n",
    "Loss.to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.1389843374490738, RMSE: 41.24155383412785\n",
      "Epoch: 1, Loss: 0.039381109178066254, RMSE: 13.512601583874106\n",
      "Epoch: 2, Loss: 0.02773537114262581, RMSE: 14.16272218453192\n",
      "Epoch: 3, Loss: 0.024204375222325325, RMSE: 27.801526867864215\n",
      "Epoch: 4, Loss: 0.023299481719732285, RMSE: 18.009024196467042\n",
      "Epoch: 5, Loss: 0.022514406591653824, RMSE: 16.056866869046445\n",
      "Epoch: 6, Loss: 0.024206873029470444, RMSE: 16.46752404569999\n",
      "Epoch: 7, Loss: 0.025684958323836327, RMSE: 23.039852733566047\n",
      "Epoch: 8, Loss: 0.022637737914919853, RMSE: 17.640329246170786\n",
      "Epoch: 9, Loss: 0.02205568738281727, RMSE: 16.991854282436154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.512601583874106"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(data, model, Loss, opt, seq_len):\n",
    "    min = 999\n",
    "    for e in range(10):\n",
    "        model.train()\n",
    "        random.shuffle(data)\n",
    "        train_data = load_all_data(data, seq_len=seq_len)\n",
    "        total_loss = 0\n",
    "        train_iter = iter(DataLoader(train_data, batch_size=32, shuffle=True))\n",
    "        counter = 0\n",
    "        for _ in range(len(train_iter)):\n",
    "            train_data, train_label, train_padding = next(train_iter)\n",
    "            train_data, train_label, train_padding = train_data.to(device), train_label.to(device), train_padding.to(device)\n",
    "            feature, out = model(train_data, train_padding)\n",
    "            out.squeeze_(2)\n",
    "            loss = Loss(out, train_label)\n",
    "            total_loss += loss\n",
    "            counter += 1\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "            opt.step()\n",
    "        rmse = validate()\n",
    "        print(\"Epoch: {}, Loss: {}, RMSE: {}\".format(e, total_loss/counter, rmse))\n",
    "        if (rmse < min):\n",
    "            min = rmse\n",
    "            torch.save(model.state_dict(), 'save/transformer.pth')\n",
    "    return min\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in val:\n",
    "            pred_sum, pred_cnt = torch.zeros(800), torch.zeros(800)\n",
    "            pred_sum.cpu()\n",
    "            valid_data = load_data(i, seq_len)\n",
    "            data_len = len(valid_data)\n",
    "            \n",
    "            valid_loader = DataLoader(valid_data, batch_size=1000)\n",
    "            valid_iter = iter(valid_loader)\n",
    "           \n",
    "            d = next(valid_iter)\n",
    "            \n",
    "            valid_data, valid_label, valid_padding = d[0].to(device), d[1], d[2].to(device)\n",
    "            _, out = model(valid_data, valid_padding)\n",
    "            out = out.squeeze(2).cpu()\n",
    "            \n",
    "            for j in range(data_len):\n",
    "                if j < seq_len-1:\n",
    "                   \n",
    "                    pred_sum[:j+1] += out[j, -(j+1):]\n",
    "                    pred_cnt[:j+1] += 1\n",
    "                elif j <= data_len-seq_len:\n",
    "                    pred_sum[j-seq_len+1:j+1] += out[j]\n",
    "                    pred_cnt[j-seq_len+1:j+1] += 1\n",
    "                else:\n",
    "                    pred_sum[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += out[j, :(data_len-j)]\n",
    "                    pred_cnt[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += 1\n",
    "            truth = torch.tensor([valid_label[j,-1] for j in range(len(valid_label)-seq_len+1)], dtype=torch.float)\n",
    "            pred_sum, pred_cnt = pred_sum[:data_len-seq_len+1], pred_cnt[:data_len-seq_len+1]\n",
    "            pred = pred_sum/pred_cnt\n",
    "            mse = float(torch.sum(torch.pow(pred-truth, 2)))\n",
    "            rmse = math.sqrt(mse/data_len)\n",
    "            total_loss += rmse\n",
    "    return total_loss*Rc/len(val)\n",
    "train(tr, model, Loss, opt, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pred, truth):\n",
    "    \"\"\"input must be tensors!\"\"\"\n",
    "    x = pred-truth\n",
    "    score1 = torch.tensor([torch.exp(-i/13)-1 for i in x if i<0])\n",
    "    score2 = torch.tensor([torch.exp(i/10)-1 for i in x if i>=0])\n",
    "    return int(torch.sum(score1)+torch.sum(score2))\n",
    "\n",
    "\n",
    "def get_pred_result(data_len, out, lb):\n",
    "    pred_sum, pred_cnt = torch.zeros(800), torch.zeros(800)\n",
    "    for j in range(data_len):\n",
    "        if j < seq_len-1:\n",
    "            pred_sum[:j+1] += out[j, -(j+1):]\n",
    "            pred_cnt[:j+1] += 1\n",
    "        elif j <= data_len-seq_len:\n",
    "            pred_sum[j-seq_len+1:j+1] += out[j]\n",
    "            pred_cnt[j-seq_len+1:j+1] += 1\n",
    "        else:\n",
    "            pred_sum[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += out[j, :(data_len-j)]\n",
    "            pred_cnt[data_len-seq_len+1-(data_len-j):data_len-seq_len+1] += 1\n",
    "    truth = torch.tensor([lb[j,-1] for j in range(len(lb)-seq_len+1)], dtype=torch.float)\n",
    "    pred_sum, pred_cnt = pred_sum[:data_len-seq_len+1], pred_cnt[:data_len-seq_len+1]\n",
    "    pred2 = pred_sum/pred_cnt\n",
    "    pred2 *= Rc\n",
    "    truth *= Rc\n",
    "    return truth, pred2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    truth, tot, tot_sc = [], 0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k in range(test_len):\n",
    "            i = next(list_iter)\n",
    "            dataset = TRANSFORMERDATA(i, seq_len)\n",
    "            data_len = len(dataset)\n",
    "            dataloader = DataLoader(dataset, batch_size=800, shuffle=0)\n",
    "            it = iter(dataloader)\n",
    "            d = next(it)\n",
    "            input, lb, msk = d[0], d[1], d[2]\n",
    "            if fake:\n",
    "                input = torch.zeros(input.shape)\n",
    "            input, msk = input.cuda(), msk.cuda()\n",
    "            #uncertainty(input, msk, data_len, lb, i)\n",
    "            _, out = net(input, msk)\n",
    "            out = out.squeeze(2).cpu()\n",
    "            truth, pred = get_pred_result(data_len, out, lb)\n",
    "            mse = float(torch.sum(torch.pow(pred-truth, 2)))\n",
    "            rmse = math.sqrt(mse/data_len)\n",
    "            tot += rmse\n",
    "            sc = score(pred, truth)\n",
    "            tot_sc += sc\n",
    "            print(\"for file {}: rmse={:.4f}, score={}\".format(i, rmse, sc))\n",
    "            print('-'*80)\n",
    "           \n",
    "    print(\"tested on [{}] files, mean RMSE = {:.4f}, mean score = {}\".format(test_len, tot/test_len, int(tot_sc/test_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.load(\"save/transformer.pth\", map_location='cuda:0')\n",
    "model.load_state_dict(x)\n",
    "data_root = \"data/units/\"\n",
    "label_root = \"data/labels/\"\n",
    "lis = os.listdir(data_root)\n",
    "test_list = [i for i in lis if i[:5] == name]\n",
    "random.shuffle(test_list)\n",
    "test_len = len(test_list)\n",
    "list_iter = iter(test_list)\n",
    "test()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('rul')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba6a37c31782f78b489b06366919d70a54943a1b5ed282f036807a93db564a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
