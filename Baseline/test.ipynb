{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'FD001'\n",
    "seq_len = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(name):\n",
    "    data_root = \"data/units/\"\n",
    "    label_root = \"data/new_labels/\"\n",
    "    lis = os.listdir(data_root)\n",
    "    data_list = [i for i in lis if i in name]\n",
    "    data, label, padding = [], [], []\n",
    "    seq_len = 30\n",
    "    Rc = 130\n",
    "\n",
    "\n",
    "\n",
    "    for n in data_list:\n",
    "        \n",
    "        raw = np.loadtxt(data_root+n)[:,2:]\n",
    "        \n",
    "        lbl = np.loadtxt(label_root+n)/Rc\n",
    "        \n",
    "        l = len(lbl)\n",
    "        if l<seq_len:\n",
    "            raise RuntimeError(\"seq_len {} is too big for file '{}' with length {}\".format(seq_len, n, l))\n",
    "        raw, lbl = torch.tensor(raw, dtype=torch.float), torch.tensor(lbl, dtype=torch.float)\n",
    "        lbl_pad_0 = [torch.ones([seq_len-i-1]) for i in range(seq_len-1)] \n",
    "        \n",
    "        data_pad_0 = [torch.zeros([seq_len-i-1,24]) for i in range(seq_len-1)]\n",
    "    \n",
    "        lbl_pad_1 = [torch.zeros([i+1]) for i in range(seq_len-1)] \n",
    "        data_pad_1 = [torch.zeros([i+1,24]) for i in range(seq_len-1)]\n",
    "        \n",
    "        data += [torch.cat([data_pad_0[i],raw[:i+1]],0) for i in range(seq_len-1)] \n",
    "        data += [raw[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "        data += [torch.cat([raw[l-seq_len+i+1:], data_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "        label += [torch.cat([lbl_pad_0[i],lbl[:i+1]],0) for i in range(seq_len-1)] \n",
    "        label += [lbl[i-seq_len+1:i+1] for i in range(seq_len-1, l)]\n",
    "        label += [torch.cat([lbl[l-seq_len+i+1:], lbl_pad_1[i]],0) for i in range(seq_len-1)]\n",
    "        padding += [torch.cat([torch.ones(seq_len-i-1), torch.zeros(i+1)],0) for i in range(seq_len-1)]   # 1 for ingore\n",
    "        padding += [torch.zeros(seq_len) for i in range(seq_len-1, l)]\n",
    "        padding += [torch.cat([torch.zeros(seq_len-i-1), torch.ones(i+1)],0) for i in range(seq_len-1)]\n",
    "    return data, label, padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"save/\"+name+\"/train\"+name+\".txt\", dtype=str).tolist()\n",
    "valid = np.loadtxt(\"save/\"+name+\"/valid\"+name+\".txt\", dtype=str).tolist()\n",
    "test = np.loadtxt(\"save/\"+name+\"/test\"+name+\".txt\", dtype=str).tolist()\n",
    "\n",
    "train_data, train_label, train_padding = load_data(train)\n",
    "valid_data, valid_label, valid_padding = load_data(valid)\n",
    "test_data, test_label, test_padding = load_data(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformer(max_len=seq_len)\n",
    "model.to('mps')\n",
    "Loss = nn.MSELoss()\n",
    "Loss.to('mps')\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, label, padding, model, Loss, opt):\n",
    "    min = 999\n",
    "    for e in range(10):\n",
    "        model.train()\n",
    "        random.shuffle(data)\n",
    "        total_loss = 0\n",
    "        iter = iter(DataLoader(data, batch_size=32, shuffle=True))\n",
    "        counter = 0\n",
    "        for _ in range(len(iter)):\n",
    "            train_data, train_label, train_padding = next(iter)\n",
    "            train_data, train_label, train_padding = train_data.to('mps'), train_label.to('mps'), train_padding.to('mps')\n",
    "            feature, out = model(train_data, train_padding)\n",
    "            out.squeeze_(2)\n",
    "            loss = Loss(out, train_label)\n",
    "            total_loss += loss\n",
    "            counter += 1\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        rmse = validate()\n",
    "        print(\"Epoch: {}, Loss: {}, RMSE: {}\".format(e, total_loss/counter, rmse))\n",
    "        if (rmse < min):\n",
    "            min = rmse\n",
    "            torch.save(model.state_dict(), 'save/transformer.pth')\n",
    "        return min\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "def validate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(valid_data)):\n",
    "            feature, out = model(valid_data[i].unsqueeze(0).to('mps'), valid_padding[i].unsqueeze(0).to('mps'))\n",
    "            out.squeeze_(2)\n",
    "            loss = Loss(out, valid_label[i].unsqueeze(0).to('mps'))\n",
    "            total_loss += loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    minn = 999\n",
    "    for e in range(epochs):\n",
    "        al, tot = 0, 0\n",
    "        net.train()\n",
    "        random.shuffle(source_list)\n",
    "        random.shuffle(target_list)\n",
    "        source_iter, target_iter = iter(source_list), iter(target_list)\n",
    "        loss2_sum, loss1_sum = 0, 0\n",
    "        bkb_sum, out_sum = 0, 0\n",
    "        cnt = 0\n",
    "        s_iter = iter(DataLoader(s_data, batch_size=args.batch_size, shuffle=True))\n",
    "        t_iter = iter(DataLoader(t_data, batch_size=args.batch_size, shuffle=True))\n",
    "        l = min(len(s_iter), len(t_iter))\n",
    "        for _ in range(l):\n",
    "            s_d, t_d = next(s_iter), next(t_iter)\n",
    "            s_input, s_lb, s_msk = s_d[0], s_d[1], s_d[2]\n",
    "            t_input, t_msk = t_d[0], t_d[2]\n",
    "            s_input, s_lb, s_msk = s_input.cuda(), s_lb.cuda(), s_msk.cuda()\n",
    "            t_input, t_msk = t_input.cuda(), t_msk.cuda()\n",
    "            s_features, s_out = net(s_input, s_msk)\n",
    "            t_features, t_out = net(t_input, t_msk) # [bts, seq_len, feature_num]\n",
    "            s_out.squeeze_(2)\n",
    "            t_out.squeeze_(2)\n",
    "            loss1 = Loss(s_out, s_lb)\n",
    "            loss1_sum += loss1\n",
    "            cnt += 1\n",
    "            if args.type == 1 or args.type == 0:\n",
    "                if args.type == 1:\n",
    "                    s_domain = D2(s_features)\n",
    "                    t_domain = D2(t_features)\n",
    "                else:\n",
    "                    s_domain = D1(s_out)\n",
    "                    t_domain = D1(t_out)\n",
    "                loss2 = advLoss(s_domain.squeeze(1), t_domain.squeeze(1), 'cuda')\n",
    "                loss2_sum += loss2\n",
    "                loss = loss1 + a*loss2\n",
    "            elif args.type == 2:\n",
    "                s_domain_bkb = D2(s_features)\n",
    "                t_domain_bkb = D2(t_features)\n",
    "                s_domain_out = D1(s_out)\n",
    "                t_domain_out = D1(t_out)\n",
    "                if e>=5:\n",
    "                    fea_loss = advLoss(s_domain_bkb.squeeze(1), t_domain_bkb.squeeze(1), 'cuda')\n",
    "                    out_loss = advLoss(s_domain_out.squeeze(1), t_domain_out.squeeze(1), 'cuda')\n",
    "                    bkb_sum += fea_loss\n",
    "                    out_sum += out_loss\n",
    "                    loss = loss1 + a*fea_loss + b*out_loss\n",
    "                else:\n",
    "                    loss = loss1\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(itertools.chain(net.parameters(), D1.parameters(), D2.parameters()), 2)\n",
    "            opt.step()    \n",
    "\n",
    "        rmse = validate()\n",
    "        if args.type == 2:\n",
    "            print(\"{}/{}| loss1={:.5f}, fea_loss={:.5f}, out_loss={:.5f}, rmse={:.5f}\".\\\n",
    "                format(e, args.epoch, loss1_sum/cnt, bkb_sum/cnt, out_sum/cnt, rmse))\n",
    "        else:    \n",
    "            print(\"{}/{}| 1={:.5f}, 2={:.5f}, rmse={:.5f}\".format(e, args.epoch, loss1, loss2_sum/cnt, rmse))\n",
    "        if rmse<minn:\n",
    "            minn = rmse\n",
    "            print(\"min={}\".format(minn))\n",
    "            if args.type == 1:\n",
    "                torch.save(net.state_dict(), \"save/final/dann_\"+source[-1]+target[-1]+\".pth\")\n",
    "            elif args.type == 0:\n",
    "                torch.save(net.state_dict(), \"save/final/out_\"+source[-1]+target[-1]+\".pth\")\n",
    "            elif args.type == 2 :\n",
    "                #torch.save(net.state_dict(), \"save/final/both_\"+source[-1]+target[-1]+\".pth\")\n",
    "                torch.save(net.state_dict(), \"online/\"+source[-1]+target[-1]+\"_net.pth\")\n",
    "                torch.save(D1.state_dict(), \"online/\"+source[-1]+target[-1]+\"_D1.pth\")\n",
    "                torch.save(D2.state_dict(), \"online/\"+source[-1]+target[-1]+\"_D2.pth\")\n",
    "        \n",
    "        if args.scheduler:\n",
    "            sch.step()\n",
    "\n",
    "    return minn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('Torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75869b7116f1291e7c10cff74bbd2a55c00e7d17b51e90358a94fff1ecb0e1dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
